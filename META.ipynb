{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 120 Json Data 추출 \n",
    "### 한글 폴더명으로 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# pip install pymysql\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "violation_ID = list(range(62, 69 + 1))\n",
    "violation_object_ID = list(range(70, 132 + 1))\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list={\n",
    "    '1' : '1 보행자도로 통행 위반',\n",
    "    '2' : '2 동승자 탑승 위반',\n",
    "    '3' : '3 안전모 미착용 위반',\n",
    "    '4' : '4 무단횡단 위반',\n",
    "    '5' : '5 횡단보도 주행 위반',\n",
    "    '6' : '6 신호 위반',\n",
    "    '7' : '7 교차로 통행방법 위반',\n",
    "    '8' : '8 정지선 위반'\n",
    "}\n",
    "\n",
    "pm_list={\n",
    "    '0' : '오토바이',\n",
    "    '1' : '자전거',\n",
    "    '2' : '킥보드',\n",
    "    '3' : '기타'\n",
    "}\n",
    "\n",
    "violation_list = {\n",
    "    '0' : '정상',\n",
    "    '1' : '위반'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectiondb():\n",
    "    _host = '218.155.74.39'\n",
    "    _uid = 'root'\n",
    "    _pwd = 'f1soft@170'\n",
    "    _db_name = 'aihub_video_73'\n",
    "    _port = 3306\n",
    "    try:\n",
    "        con = pymysql.connect(host=_host, user=_uid, password=_pwd, database=_db_name, port=int(_port), autocommit=True)\n",
    "        return con\n",
    "    except Exception as e:\n",
    "        return get_error_msg(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDirectory(accident_type, pm, violation, directory = '.\\\\json120\\\\nor'): \n",
    "    try: \n",
    "        class_dir = class_list[f'{str(accident_type)}']\n",
    "        pm_dir = pm_list[f'{str(pm)}']\n",
    "        violation_dir = violation_list[f'{str(violation)}']\n",
    "        if not os.path.exists(directory): \n",
    "            os.makedirs(directory) \n",
    "        if not os.path.exists(f'{directory}\\\\{class_dir}'):\n",
    "            os.makedirs(f'{directory}\\\\{class_dir}')\n",
    "        if not os.path.exists(f'{directory}\\\\{class_dir}\\\\{pm_dir}'):\n",
    "            os.makedirs(f'{directory}\\\\{class_dir}\\\\{pm_dir}')\n",
    "        if not os.path.exists(f'{directory}\\\\{class_dir}\\\\{pm_dir}\\\\{violation_dir}'):\n",
    "            os.makedirs(f'{directory}\\\\{class_dir}\\\\{pm_dir}\\\\{violation_dir}')\n",
    "    except OSError: \n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "    return f'{directory}\\\\{class_dir}\\\\{pm_dir}\\\\{violation_dir}\\\\' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Data(DATA_ID = ''):\n",
    "    where = ''\n",
    "    if(DATA_ID != ''):\n",
    "        where = f\"WHERE A.DATA_ID = '{DATA_ID}'\"\n",
    "    sql = f'''\n",
    "        SELECT \n",
    "                A.DATA_ID,\n",
    "                A.FRAME,\n",
    "                replace(A.FILENAME, '.mp4', '') AS FILENAME,\n",
    "                COUNT(*) AS CNT\n",
    "        FROM `DATA` AS A\n",
    "            LEFT JOIN META AS B\n",
    "                ON A.DATA_ID = B.DATA_ID\n",
    "        {where}\n",
    "        ORDER BY A.DATA_ID ASC\n",
    "    '''\n",
    "    with connectiondb() as con:\n",
    "        with con.cursor() as cur:\n",
    "            cur.execute(sql)\n",
    "            result = cur.fetchall()\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Meta(DATA_ID):\n",
    "    sql = f'''\n",
    "        SELECT A.META_ID,\n",
    "            A.LABEL_ID,\n",
    "            A.LABEL_TYPE,\n",
    "            IFNULL(A.INFO, '{{\"startFrame\":0,\"endFrame\":0,\"rectData\":null}}') as INFO,\n",
    "            C.`NAME` AS NAME\n",
    "        FROM META A\n",
    "            LEFT OUTER JOIN DATA B\n",
    "                ON A.DATA_ID=B.DATA_ID\n",
    "            LEFT JOIN `LABEL` AS C\n",
    "                ON A.LABEL_ID = C.LABEL_ID\n",
    "        WHERE A.DATA_ID={DATA_ID} ORDER BY A.META_ID ASC\n",
    "    '''\n",
    "    with connectiondb() as con:\n",
    "        with con.cursor() as cur:\n",
    "            cur.execute(sql)\n",
    "            result = cur.fetchall()\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Data_Detail(DATA_ID):\n",
    "    sql = f'''\n",
    "    SELECT \n",
    "        left(D.FILENAME, 7) AS VIDEO_ID,\n",
    "        D.DURATION,\n",
    "        DD.*,\n",
    "        IFNULL(M.INFO, '{{\"startFrame\":0,\"endFrame\":0,\"rectData\":null}}') as INFO\n",
    "    FROM `DATA` AS D\n",
    "    LEFT JOIN `DATA_DETAIL` AS DD\n",
    "        ON D.DATA_ID = DD.DATA_ID\n",
    "    LEFT JOIN `META` AS M\n",
    "        ON D.DATA_ID = M.DATA_ID\n",
    "        AND M.LABEL_TYPE = 'VIDEO_TRIMMING'\n",
    "    WHERE D.DATA_ID = {DATA_ID}\n",
    "    ORDER BY D.DATA_ID\n",
    "    '''\n",
    "    with connectiondb() as con:\n",
    "        with con.cursor() as cur:\n",
    "            cur.execute(sql)\n",
    "            result = cur.fetchall()\n",
    "    return np.array(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_meta_list(DATA_ID):\n",
    "    for Data in get_Data(DATA_ID):\n",
    "        _data_ID = Data[0]\n",
    "        _frame = int(Data[1])\n",
    "        _fileName = Data[2]\n",
    "        FrameData = dict()\n",
    "        \n",
    "        # total_meta(프레임 기준 배열) => frame, annotations, cai_annotations\n",
    "        # 데이터 내 라벨링 메타\n",
    "        for meta in get_Meta(_data_ID) :\n",
    "            _meta_ID = meta[0]\n",
    "            _label_ID = meta[1]\n",
    "            _label_type = meta[2]\n",
    "            _meta_data = json.loads(meta[3])\n",
    "            _label_name = meta[4]\n",
    "            \n",
    "            startFrame=int(_meta_data[\"startFrame\"])\n",
    "            endFrame=int(_meta_data[\"endFrame\"])\n",
    "            # 메타데이터의 프레임\n",
    "            for i in range(startFrame,endFrame + 1):\n",
    "                # i 는 프레임번호\n",
    "                annotations = []\n",
    "                real_index = i - startFrame \n",
    "                try:\n",
    "                    if _label_type == 'VIDEO_BBOX':\n",
    "\n",
    "\n",
    "                        b_box = _meta_data[\"rectData\"][real_index]\n",
    "                        # BBOX\n",
    "                        annotations.append('bbox')\n",
    "                        bbox = []\n",
    "                        _x1_y1_x2_y2 = []\n",
    "                        _x1_y1_x2_y2.append(float(b_box['left']))\n",
    "                        _x1_y1_x2_y2.append(float(b_box['top']))\n",
    "                        _x1_y1_x2_y2.append(float(b_box['left']) + int(b_box['width']))\n",
    "                        _x1_y1_x2_y2.append(float(b_box['top']) + int(b_box['height']))\n",
    "                        bbox.append(_x1_y1_x2_y2)\n",
    "                        annotations.append(bbox)\n",
    "\n",
    "                    elif _label_type == 'VIDEO_SEGMENTATION':\n",
    "                        segmentation = _meta_data[\"polyData\"][real_index][\"segmentation\"]\n",
    "                        #print(_meta_ID, real_index)\n",
    "                        # SEGMENTATION\n",
    "                        annotations.append('polygon')\n",
    "                        polygon = []\n",
    "                        # polygon 배열 \n",
    "                        for seg in segmentation:\n",
    "                            _x_y = []\n",
    "                            _x_y.append(float(seg['x']))\n",
    "                            _x_y.append(float(seg['y']))\n",
    "                            polygon.append(_x_y)\n",
    "                        annotations.append(polygon)\n",
    "                    else:\n",
    "                         # TRIMMING\n",
    "                        annotations.append('trimming')\n",
    "                        annotations.append(0)\n",
    "                    annotations.append(_meta_ID)\n",
    "                    annotations.append(_label_ID)\n",
    "                    annotations.append(_label_name)\n",
    "                    # 프레임별 데이터로 추가\n",
    "                    if FrameData.get(f'{i}') :\n",
    "                        FrameData[f'{i}'].append(annotations)\n",
    "                    else:\n",
    "                        FrameData[f'{i}'] = []    \n",
    "                        FrameData[f'{i}'].append(annotations)\n",
    "                except:\n",
    "                    if not os.path.isfile(r'C:\\Repositories\\Python\\73\\cnt120\\json120\\log.txt'): \n",
    "                        f = open(\"새파일.txt\", 'w')\n",
    "                        f.close()\n",
    "                    with open(r'C:\\Repositories\\Python\\73\\cnt120\\json120\\log.txt', 'a') as log_file:\n",
    "                        log_file.write(f'메타테이블 에러 : DataID : {_data_ID}  AnnotationID : {_meta_ID}\\n')\n",
    "                    print(f'메타테이블 에러 : DataID : {_data_ID}  AnnotationID : {_meta_ID}')\n",
    "\n",
    "    return dict(OrderedDict(sorted(FrameData.items(), key=lambda t: int(t[0])))), _fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_Cai_annotation(_value):\n",
    "    _cai_annotation = OrderedDict()\n",
    "    # _cai_annotations 내에 배열\n",
    "    _cai_subject_id = []\n",
    "    _cai_object_id = []\n",
    "    for val in _value:\n",
    "        # 위반 어노테이션\n",
    "        if np.isin(int(val[3]), violation_object_ID):\n",
    "            if val[0] == 'bbox':\n",
    "                _cai_object_id.append(val[3])\n",
    "            elif val[0] == 'polygon':\n",
    "                _cai_subject_id.append(val[3])\n",
    "        elif np.isin(int(val[3]), violation_ID):\n",
    "            _cai_annotation[\"category_id\"] = str(int(val[3]) - 61)\n",
    "        \n",
    "        if _cai_annotation.get(\"category_id\") == None:\n",
    "            _cai_annotation[\"category_id\"] = str(0)\n",
    "        _cai_annotation[\"subject_id\"] = _cai_subject_id\n",
    "        _cai_annotation[\"object_id\"] = _cai_object_id\n",
    "    return _cai_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(DataList,used_pass=True):\n",
    "    global count\n",
    "    # 데이터 리스트 \n",
    "    for Data in DataList :\n",
    "        \n",
    "        #json_data = []\n",
    "        _json_dict = OrderedDict()\n",
    "        DataMeta, fileName = set_meta_list(Data)\n",
    "        \n",
    "        # 다양성 정보\n",
    "        _info = OrderedDict()\n",
    "        _description = OrderedDict()\n",
    "        _annotations = OrderedDict()\n",
    "        data_detail = get_Data_Detail(Data)\n",
    "        # 이미 파일이 있으면 PASS\n",
    "        if (data_detail[2] == None) or\\\n",
    "            (os.path.exists(f'.\\\\json120\\\\{class_list[data_detail[11]]}\\\\{pm_list[data_detail[10]]}\\\\{violation_list[data_detail[9]]}\\\\{fileName}.json')): \n",
    "            continue\n",
    "        _info[\"video_id\"] = data_detail[0]\n",
    "        _info[\"clip_id\"] = data_detail[3]\n",
    "        _info[\"data_id\"] = data_detail[2]\n",
    "        _info[\"date\"] = data_detail[5]\n",
    "        _info[\"device\"] = data_detail[4]\n",
    "        _info[\"is_scripted\"] = data_detail[6]\n",
    "        _info[\"time\"] = data_detail[7]\n",
    "        _info[\"weather\"] = data_detail[8]\n",
    "        \n",
    "        _description[\"violation\"] = data_detail[9]\n",
    "        _description[\"PM\"] = data_detail[10]\n",
    "        _description[\"violation_type\"] = data_detail[11]\n",
    "        _description[\"duration\"] = float(data_detail[1])\n",
    "        json_trimming = json.loads(data_detail[12])\n",
    "        _annotations[\"startFrame\"] = json_trimming[\"startFrame\"]\n",
    "        _annotations[\"endFrame\"] = json_trimming[\"endFrame\"]\n",
    "        #_json_detail[\"Trimming\"] = data_detail[12]\n",
    "        #_json_detail[\"Trimming\"].pop('rectData')\n",
    "        \n",
    "        _json_dict[\"info\"] = _info\n",
    "        _json_dict[\"description\"] = _description\n",
    "        \n",
    "        \n",
    "        _annotations_frame = []\n",
    "        # 한데이터에 대한 반복문\n",
    "        for key, value in DataMeta.items():\n",
    "            # 하위에 추가될 메타 변수명 선언\n",
    "            _json = OrderedDict()\n",
    "            _annotation = []\n",
    "            violation_flag = False\n",
    "            # 프레임 정보 추가\n",
    "            _json[\"frame\"] = int(key)\n",
    "            # 한 프레임에 대한 반복문\n",
    "            for detail in value :\n",
    "                # 어노테이션 변수 선언\n",
    "                _anno_info = OrderedDict()\n",
    "                \n",
    "                if detail[0] in ['bbox', 'polygon']:\n",
    "                    # bbox, polygon, category_id 추가\n",
    "                    _anno_info[\"annotation_id\"] = detail[2]\n",
    "                    _anno_info[\"annotation_type\"] = detail[0]\n",
    "                    _anno_info[\"annotation_info\"] = detail[1]\n",
    "                    _anno_info[\"category_id\"] = detail[3]\n",
    "                    _anno_info[\"category_name\"] = detail[4]\n",
    "                    _annotation.append(_anno_info)\n",
    "                # else :\n",
    "                #    violation_flag = True\n",
    "\n",
    "            _json[\"frame_annotation\"] = _annotation\n",
    "\n",
    "            #if violation_flag == True:\n",
    "            #    print('cai')\n",
    "            #    violation_flag = False\n",
    "            _cai_annotations = []\n",
    "            _cai_annotations.append(Make_Cai_annotation(value))\n",
    "            _json[\"cai_annotation\"] = _cai_annotations\n",
    "            \n",
    "            _annotations_frame.append(_json)\n",
    "            \n",
    "        _annotations[\"anno_info\"] = _annotations_frame\n",
    "        _json_dict[\"annotations\"] = _annotations\n",
    "        # json_data.append(_json_dict)\n",
    "        with open(f'{createDirectory(data_detail[11], data_detail[10], data_detail[9])}\\\\{fileName}.json', 'w', encoding='utf-8') as make_file:\n",
    "            count = count + 1\n",
    "            json.dump(_json_dict, make_file, ensure_ascii = False, indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_id_accident(accident_type, except_data_id = []):\n",
    "    except_where = ''\n",
    "    if len(except_data_id) > 0:\n",
    "        except_where = f'''AND D.DATA_ID NOT IN ({','.join(map(str, except_data_id))})'''\n",
    "    sql = f'''\n",
    "            SELECT D.DATA_ID FROM DATA AS D\n",
    "    LEFT JOIN DATASET AS DS\n",
    "        ON D.DATASET_ID = DS.DATASET_ID\n",
    "            LEFT JOIN `DATA_DETAIL` AS DD\n",
    "        ON D.DATA_ID = DD.DATA_ID\n",
    "    \n",
    "\n",
    "    WHERE D.CONFIRM_STATUS = 3\n",
    "    AND DD.DEVICE IN (1, 2)\n",
    "    AND MID(D.FILENAME, 17,1) = '{accident_type}'\n",
    "    AND DS.TITLE LIKE '%abies%'\n",
    "    {except_where}\n",
    "    ''' \n",
    "    with connectiondb() as con:\n",
    "        with con.cursor() as cur:\n",
    "            cur.execute(sql)\n",
    "            result = np.array(cur.fetchall()).reshape(-1,)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5248/3155460794.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# accident_type 에 따른 json 출력\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_data_id_accident\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'JSON파일 총 변환량 : {count}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5248/2915474101.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(DataList, used_pass)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{createDirectory(data_detail[11], data_detail[10], data_detail[9])}\\\\{fileName}.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmake_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_json_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmake_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_ascii\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# a debuggability cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# accident_type 에 따른 json 출력\n",
    "for i in [1,2,3,4,5,6,8]:\n",
    "    execute(get_data_id_accident(i))\n",
    "print(f'JSON파일 총 변환량 : {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Work : 90\n"
     ]
    }
   ],
   "source": [
    "execute([90])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
